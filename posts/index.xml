<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Lochana Perera</title><link>https://fivetwentythree.github.io/personal-blog/posts/</link><description>Recent content in Posts on Lochana Perera</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 16 Jul 2025 16:52:57 +1000</lastBuildDate><atom:link href="https://fivetwentythree.github.io/personal-blog/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Attention is all you need</title><link>https://fivetwentythree.github.io/personal-blog/posts/second-post/</link><pubDate>Wed, 16 Jul 2025 16:52:57 +1000</pubDate><guid>https://fivetwentythree.github.io/personal-blog/posts/second-post/</guid><description>&lt;p>It was high tide&amp;ndash;spring tide, if you will&amp;ndash;at half past-six o&amp;rsquo;clock
on a warm June evening: not the commonplace ebb and flow of a vulgar
river; but the mighty tide of fashion&amp;rsquo;s wonderful sea, surging
westward, &lt;a href="https://docs.mathjax.org/en/stable/start.html#linking-your-copy-of-mathjax-into-a-web-page">this&lt;/a> under the dusty elms and lindens of the Lady&amp;rsquo;s Mile.&lt;span class="sidenote sidenote-right">
this is a side note about this specific paragraph The pouncing
proprietor, with the leathern pouch at his side, has hard work to
collect his rents, so rapidly do his customers come and go, and is
distracted by vague fears of levanting tenants and bad debts.
&lt;/span>
If you had driven round this very park between four and five on this
very afternoon, you would have been gratified by the sight of some
half-dozen &lt;a href="https://docs.mathjax.org/en/stable/start.html#linking-your-copy-of-mathjax-into-a-web-page">nursemaids&lt;/a> with their straggling charges, an occasional girl
and perambulator, a picturesque life guardsman here and there, making a
little spot of crimson amongst the wavering shadows of the trees, a few
hulking idlers in corduroy and bluchers, and a tipsy female sleeping
on the grass.&lt;/p>
&lt;p>&lt;span class="sidenote sidenote-left">
this image show how this is normaally done in the past and this is how we do it in present &lt;img src="https://fivetwentythree.github.io/personal-blog/assets/images/1.png"
alt="this_is_a_new_image"
srcset="https://fivetwentythree.github.io/personal-blog/images/1_hu_74715f382c15d7ba.webp 200w, https://fivetwentythree.github.io/personal-blog/images/1_hu_dbf332de2fe9c193.webp 400w, https://fivetwentythree.github.io/personal-blog/images/1_hu_fee156652223f56.webp 800w, https://fivetwentythree.github.io/personal-blog/images/1_hu_a4c2d58288265806.webp 1200w"
sizes="(max-width: 600px) 100vw, 600px"
loading="lazy"
>
&lt;/span>&lt;span class="sidenote sidenote-right">
$$
\int_0^\infty e^{-x^2} dx = \frac{\sqrt{\pi}}{2}
$$
&lt;/span>&lt;/p>
&lt;p>Now the excited policemen have enough to do to keep the
four ranks of carriages in line, and to rescue foot-passengers from
the pawing hoofs of three-hundred-guinea steeds.&lt;/p>
&lt;span class="sidenote sidenote-right">
&lt;img src="https://fivetwentythree.github.io/personal-blog/assets/images/4.png"
srcset="https://fivetwentythree.github.io/personal-blog/images/4_hu_50c7e311d22dd49d.webp 200w, https://fivetwentythree.github.io/personal-blog/images/4_hu_f90a2828ef952c77.webp 400w, https://fivetwentythree.github.io/personal-blog/images/4_hu_4dc6660f0f0da72.webp 800w, https://fivetwentythree.github.io/personal-blog/images/4_hu_17aff468d2939550.webp 1200w"
sizes="(max-width: 600px) 100vw, 600px"
loading="lazy"
>
&lt;/span>
&lt;p>The walk under the trees is as crowded as the enclosure at Ascot, and the iron chairs are
as fully occupied as the seats in a fashionable chapel. The pouncing
proprietor, with the leathern pouch at his side, has hard work to
collect his rents, so rapidly do his customers come and go, and is
distracted by vague fears of levanting tenants and bad debts.&lt;/p>
&lt;p>&lt;img src="https://fivetwentythree.github.io/personal-blog/assets/images/2.png"
alt="book_cover"
srcset="https://fivetwentythree.github.io/personal-blog/images/2_hu_82533c6ade72b62.webp 200w, https://fivetwentythree.github.io/personal-blog/images/2_hu_fd8674fc136d645f.webp 400w, https://fivetwentythree.github.io/personal-blog/images/2_hu_37b5332e65f8a739.webp 800w, https://fivetwentythree.github.io/personal-blog/images/2_hu_434f864c9eff9c92.webp 1200w"
sizes="(max-width: 600px) 100vw, 600px"
loading="lazy"
>&lt;/p>
&lt;p>On all the length of the rails between Hyde-Park Corner and the Serpentine
there is scarcely room for one lounger more, for the rule of fashion
is so subtile a bondage, that it has compelled millions of people who
never in all their lives have spoken to one another to wear the same
order of garments, and talk the same slang, and ride in the same kind
of carriages, and eat the same class of dinners, and congregate in
the same places, at the same hour, year after year, and century after
century, from the earliest dawn of civilisation until to-day.&lt;/p>
&lt;div class="highlight" title="test.py">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">hello_world&lt;/span>&lt;span class="p">():&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;Hello, world!&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>We are a wealthy nation, the political economist tells the poor
man, and our superfluous wealth must find employment somehow
or other. Hench the crush of high-stepping horses, the crowd of
three-hundred-guinea barouches; the flutter of costly garments rustling
in the summer air, the glitter and splendour which pervades every
object, until it seems almost as if the superfluous gold were melted
into the atmosphere, and all the female population were so many Miss
Kilmanseggs.&lt;/p>
&lt;p>The lounger on the rails may for the moment find it almost
difficult to believe that hungry women and gaunt haggard-looking men
can have any place in the world of which this dazzling region is a
part: but he need only look backward, under the shadow of the trees, to
see poverty and crime prowling side by side in their rags.&lt;/p>
&lt;p>Yet at the worst, the dazzle and the glitter are good for trade; and it is better that the tide of wealth should be rolling to and fro along the Lady&amp;rsquo;s
Mile than locked in a miser&amp;rsquo;s coffers or given in alms to professional
beggars at a church-door. Some part of the superfluous gold must pass
through the horny hands of labour before it can be transmuted into
C-springs or patent axles, Honiton lace or Spitalfields silk; and
perhaps the safest of all philosophy is that which accepts the doctrine
that &amp;ldquo;whatever is, is right.&amp;rdquo;&lt;/p></description></item><item><title>Playing Atari with deep reinforcement learning</title><link>https://fivetwentythree.github.io/personal-blog/posts/deep-rl/</link><pubDate>Wed, 16 Jul 2025 16:52:57 +1000</pubDate><guid>https://fivetwentythree.github.io/personal-blog/posts/deep-rl/</guid><description>&lt;span class="sidenote sidenote-right">
&lt;p>&lt;img src="https://fivetwentythree.github.io/personal-blog/assets/images/atari-breakout-display.jpg.webp"
alt="atari-breakout"
srcset="https://fivetwentythree.github.io/personal-blog/images/atari-breakout-display.jpg_hu_f9658db51bb3bea2.webp 200w, https://fivetwentythree.github.io/personal-blog/images/atari-breakout-display.jpg_hu_c2fe099d017affa1.webp 400w, https://fivetwentythree.github.io/personal-blog/images/atari-breakout-display.jpg_hu_be4ed6fd74fad76.webp 800w, https://fivetwentythree.github.io/personal-blog/images/atari-breakout-display.jpg_hu_a2c0896f080346b2.webp 1200w"
sizes="(max-width: 600px) 100vw, 600px"
loading="lazy"
>&lt;/p>
&lt;h3 id="atari-breakout">Atari Breakout&lt;/h3>
&lt;p>Breakout is a seminal arcade video game developed by Atari, Inc., and released in 1976. Designed by Nolan Bushnell and Steve Bristow, with engineering by Steve Wozniak, it evolved from Atari&amp;rsquo;s Pong and became a cornerstone of early gaming.&lt;/p>
&lt;p>&lt;strong>Gameplay&lt;/strong>: Players control a horizontal paddle at the bottom of the screen to bounce a ball toward a wall of colored bricks at the top. The ball destroys bricks on contact, scoring points, while deflecting off walls and the paddle. The goal is to clear all bricks across levels without letting the ball fall past the paddle (losing a life). Power-ups and speed increases add challenge; it&amp;rsquo;s single-player with simple controls (knob or joystick).&lt;/p>
&lt;p>&lt;strong>Mechanics and Features&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Core Loop&lt;/strong>: Ball physics simulate realistic bounces; breaking bricks can accelerate the ball or introduce multiples.&lt;/li>
&lt;li>&lt;strong>Scoring&lt;/strong>: Points vary by brick color/position; high scores encourage replay.&lt;/li>
&lt;li>&lt;strong>Lives and Progression&lt;/strong>: Start with limited lives; levels advance with faster gameplay and varied brick layouts.&lt;/li>
&lt;li>&lt;strong>Hardware&lt;/strong>: Originally an arcade cabinet with black-and-white display (color overlays added); ports to Atari 2600 (1978) popularized home versions.&lt;/li>
&lt;/ul>
&lt;/span>
&lt;p>The paper introduces a novel agent, which they call a Deep Q-Network (DQN), that learns to play Atari games by looking only at the screen pixels, just like a human. The key innovations were:
&lt;span class="sidenote sidenote-left">
&lt;img src="https://fivetwentythree.github.io/personal-blog/assets/images/atari-paper.png"
alt="atari paper"
srcset="https://fivetwentythree.github.io/personal-blog/images/atari-paper_hu_7a806f9ce82d4c1f.webp 200w, https://fivetwentythree.github.io/personal-blog/images/atari-paper_hu_b66928f20385b477.webp 400w, https://fivetwentythree.github.io/personal-blog/images/atari-paper_hu_80563ffb8ab6f921.webp 800w, https://fivetwentythree.github.io/personal-blog/images/atari-paper_hu_1aebfc9ec2717ebf.webp 1200w"
sizes="(max-width: 600px) 100vw, 600px"
loading="lazy"
>
&lt;/span>&lt;/p>
&lt;p>1.End-to-End Learning: Using a deep Convolutional Neural Network (CNN) to directly process raw pixels and output action values, eliminating the need for hand-crafted features.&lt;/p>
&lt;p>2.Experience Replay: Storing the agent&amp;rsquo;s experiences (state, action, reward, next state) in a memory buffer and then randomly sampling from this buffer to train the network. This breaks the correlation between consecutive samples and smooths the data distribution, stabilizing learning.&lt;/p>
&lt;p>3.Target Network (A crucial detail from the follow-up 2015 paper, but implied here): Using a separate, fixed network to generate the target Q-values for the Bellman update. This prevents the target from rapidly changing, which further stabilizes training.&lt;/p>
&lt;h3 id="lets-build-this-components-in-python">lets build this components in python&lt;/h3>
&lt;p>Prerequisites&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">pip&lt;/span> &lt;span class="n">install&lt;/span> &lt;span class="n">torch&lt;/span> &lt;span class="n">gymnasium&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">atari&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="n">ale&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">py&lt;/span> &lt;span class="n">numpy&lt;/span> &lt;span class="n">opencv&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">python&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="step-1-setting-up-the-environment--preprocessing">Step 1: Setting up the Environment &amp;amp; Preprocessing&lt;/h3>
&lt;p>The paper specifies a series of preprocessing steps to make learning more manageable.&lt;/p>
&lt;ul>
&lt;li>Convert the image to grayscale.&lt;/li>
&lt;li>Downsample the image to 110x84.&lt;/li>
&lt;li>Crop the image to an 84x84 region that captures the play area.&lt;/li>
&lt;li>Stack the last 4 frames together to give the network a sense of motion (e.g., the ball&amp;rsquo;s velocity).&lt;/li>
&lt;/ul>
&lt;p>⠀We can encapsulate this logic in a gymnasium wrapper.
&lt;span class="sidenote sidenote-right">
How to use it:
env = gym.make(&amp;ldquo;ALE/Breakout-v5&amp;rdquo;)
Use the full name with &amp;ldquo;ALE/&amp;rdquo;
processed_env = AtariPreprocessing(env)
state, info = processed_env.reset()
print(f&amp;quot;Observation shape: {state.shape}&amp;quot;) # Should be (4, 84, 84)
&lt;/span>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">gymnasium&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">gym&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">cv2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">numpy&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">np&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">collections&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">deque&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">AtariPreprocessing&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">gym&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Wrapper&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> A wrapper for Atari environments that preprocesses observations as described
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> in the DQN paper.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> - Grayscale and resize frames
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> - Stack the last 4 frames
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">env&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">frame_stack_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">super&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">env&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">frame_stack_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">frame_stack_size&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">frames&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">deque&lt;/span>&lt;span class="p">([],&lt;/span> &lt;span class="n">maxlen&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">frame_stack_size&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Define the new observation space shape&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># The shape is (frame_stack_size, height, width)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">observation_space&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">gym&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">spaces&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Box&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">low&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">high&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">255&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">shape&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">frame_stack_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">84&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">84&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dtype&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">uint8&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">_preprocess_frame&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">frame&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Convert to grayscale&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">frame&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">cv2&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cvtColor&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">frame&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cv2&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">COLOR_RGB2GRAY&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Resize to 110x84, then crop to 84x84&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">frame&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">cv2&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">resize&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">frame&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mi">84&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">84&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">interpolation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">cv2&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">INTER_AREA&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">frame&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">reset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="n">kwargs&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Reset the underlying environment&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">observation&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">info&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">env&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">reset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">**&lt;/span>&lt;span class="n">kwargs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Preprocess the first frame and fill the deque&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">processed_frame&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_preprocess_frame&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">observation&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">_&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">frame_stack_size&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">frames&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">processed_frame&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_get_observation&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">info&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">step&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">action&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">observation&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">reward&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">terminated&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">truncated&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">info&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">env&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">step&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">action&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Preprocess the new frame and add it to the deque&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">processed_frame&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_preprocess_frame&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">observation&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">frames&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">processed_frame&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">_get_observation&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">reward&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">terminated&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">truncated&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">info&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">_get_observation&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Return the stacked frames as a single numpy array&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">frames&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>This can be way more beautiful</title><link>https://fivetwentythree.github.io/personal-blog/posts/my-first-post/</link><pubDate>Wed, 16 Jul 2025 16:52:57 +1000</pubDate><guid>https://fivetwentythree.github.io/personal-blog/posts/my-first-post/</guid><description>&lt;h3 id="or-can-it-be-can-this-be-">or can it be? can this be ?&lt;/h3>
&lt;p>Over the past year, robotics has been catching up with the LLM era. Pi’s π0.5 can clean unseen homes. Tesla’s Optimus can follow natural language cooking instructions. These systems are extremely impressive, but they feel stuck in a utilitarian mindset of robotic appliances.&lt;/p>
&lt;span class="sidenote sidenote-right">
&lt;p>this has been argued to me the most heneious crimes perpetrated by the criminals&lt;/p>
&lt;p>&lt;img src="https://fivetwentythree.github.io/personal-blog/assets/images/3.png"
srcset="https://fivetwentythree.github.io/personal-blog/images/3_hu_f2e9e60e3fde6d32.webp 200w, https://fivetwentythree.github.io/personal-blog/images/3_hu_cb2b4e329abe710c.webp 400w, https://fivetwentythree.github.io/personal-blog/images/3_hu_7612a848012563ef.webp 800w, https://fivetwentythree.github.io/personal-blog/images/3_hu_b0763d2c26e1c4bc.webp 1200w"
sizes="(max-width: 600px) 100vw, 600px"
loading="lazy"
>&lt;/p>
&lt;/span>
&lt;span class="sidenote sidenote-left">
&lt;img src="https://fivetwentythree.github.io/personal-blog/assets/images/2.png"
alt="image"
srcset="https://fivetwentythree.github.io/personal-blog/images/2_hu_82533c6ade72b62.webp 200w, https://fivetwentythree.github.io/personal-blog/images/2_hu_fd8674fc136d645f.webp 400w, https://fivetwentythree.github.io/personal-blog/images/2_hu_37b5332e65f8a739.webp 800w, https://fivetwentythree.github.io/personal-blog/images/2_hu_434f864c9eff9c92.webp 1200w"
sizes="(max-width: 600px) 100vw, 600px"
loading="lazy"
>
&lt;/span>
&lt;p>For these future robots to live with us, they must be expressive. Expressiveness communicates internal state such as intent, attention, and confidence. Beyond its functional utility as a communication channel, expressiveness makes interactions feel natural. Without it, you get the textbook uncanny valley effect.&lt;/p>
&lt;p>Earlier this year, I came across Apple’s ELEGNT paper, which frames this idea rigorously through a Pixar-like lamp to show how posture and timing alone can convey intention. Around the same time, I discovered SpiRobs, a soft tentacle robot that feels oddly alive with just simple movements. One system was carefully designed to express intent while the other just moved, yet somehow felt like it had intent. That difference was interesting. I started building Shoggoth Mini as a way to explore it more directly. Not with a clear goal, but to see what would happen if I pushed embodiment into stranger territory. This post retraces that process, the happy accidents, and what I learned about building robots.&lt;/p></description></item></channel></rss>